{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, imgs, labels):\n",
    "        super().__init__()\n",
    "        self.imgList = []\n",
    "        self.labelList = []\n",
    "        for i in range(len(imgs)):\n",
    "            img = cv2.resize(imgs[i], (112,112))/255.0\n",
    "            img = img.astype(np.float32)\n",
    "            imgTensor = torch.from_numpy(img.transpose((2, 0, 1)))\n",
    "            self.imgList.append(imgTensor)\n",
    "            self.labelList.append(labels[i])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.imgList[index], self.labelList[index]\n",
    "    def __len__(self):\n",
    "        return len(self.labelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channel, k_size, pad=1, s=1, dilation=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channel, kernel_size=k_size, padding=pad, stride = s, dilation=dilation)\n",
    "        self.batchNorm = nn.BatchNorm2d(out_channel)\n",
    "        self.actfunction = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchNorm(x)\n",
    "        x = self.actfunction(x)\n",
    "        return x\n",
    "\n",
    "class Fullyconnect(nn.Module):\n",
    "    def __init__(self, in_channels, out_channel):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(in_channels, out_channel)\n",
    "        self.actfunction = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.actfunction(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Architecture(nn.Module):\n",
    "    def __init__(self, numclass = 10):\n",
    "        super().__init__()\n",
    "        self.convs = nn.Sequential(  CNNBlock(in_channels = 3, out_channel = 32, k_size = 3),\n",
    "                                    nn.MaxPool2d(kernel_size = 2,stride= 2),\n",
    "                                    CNNBlock(in_channels =32, out_channel =64, k_size =3),\n",
    "                                    nn.MaxPool2d(kernel_size = 2,stride= 2),\n",
    "                                    CNNBlock(in_channels =64, out_channel =128, k_size =3),\n",
    "                                    nn.AdaptiveAvgPool2d((3,3)),)\n",
    "        self.fc = Fullyconnect(3*3*128, numclass)\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return F.softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ce_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        return self.loss(output, target.long())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = './train/train/'\n",
    "label_dict = {'Bald': 0, 'Black_Hair': 1, 'Blond_Hair': 2,  \n",
    "            'Brown_Hair': 3,'Gray_Hair': 4, 'Receding_Hairline': 5}\n",
    "\n",
    "imgPathList = os.listdir(imgPath)\n",
    "\n",
    "allImgList = []\n",
    "allLabelList = []\n",
    "randomList = []\n",
    "\n",
    "trainImgList = []\n",
    "trainLabelList = []\n",
    "\n",
    "valImgList = []\n",
    "valLabelList = []\n",
    "\n",
    "for f in imgPathList:\n",
    "    for imgName in os.listdir( imgPath + f ):\n",
    "        img = cv2.imread(imgPath + f + '/' + imgName)\n",
    "        allImgList.append(img)\n",
    "        allLabelList.append(label_dict[f])\n",
    "\n",
    "while(1):\n",
    "    rint = random.randint(0,len(allImgList))\n",
    "    if rint not in randomList:\n",
    "        randomList.append(rint)\n",
    "    if len(randomList)> len(allImgList)*0.2:\n",
    "        break\n",
    "\n",
    "for i in range(len(allImgList)):\n",
    "    if i in randomList:\n",
    "        valImgList.append(allImgList[i])\n",
    "        valLabelList.append(allLabelList[i])\n",
    "    else:\n",
    "        trainImgList.append(allImgList[i])\n",
    "        trainLabelList.append(allLabelList[i])\n",
    "\n",
    "trainDataset = ImageDataset(trainImgList, trainLabelList)\n",
    "valDataset = ImageDataset(valImgList, valLabelList)\n",
    "\n",
    "dataLoaderTrain = torch.utils.data.DataLoader(  trainDataset,\n",
    "                                                batch_size = 64,\n",
    "                                                shuffle = True,\n",
    "                                                num_workers = 0,\n",
    "                                                drop_last = True)\n",
    "\n",
    "dataLoaderVal = torch.utils.data.DataLoader(valDataset,\n",
    "                                            batch_size = 64,\n",
    "                                            shuffle = True,\n",
    "                                            num_workers = 0,\n",
    "                                            drop_last = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Architecture(numclass = 6).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
    "ceLoss = ce_loss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch time :  1.8037354946136475\n",
      "1 epoch time :  1.1136300563812256\n",
      "2 epoch time :  0.8131828308105469\n",
      "3 epoch time :  0.839240312576294\n",
      "4 epoch time :  0.8883223533630371\n",
      "5 epoch time :  0.7839264869689941\n",
      "6 epoch time :  0.8766829967498779\n",
      "7 epoch time :  0.821087121963501\n",
      "8 epoch time :  0.7821059226989746\n",
      "9 epoch time :  0.8038580417633057\n",
      "10 epoch time :  0.8471462726593018\n",
      "11 epoch time :  0.9104475975036621\n",
      "12 epoch time :  0.777777910232544\n",
      "13 epoch time :  0.8453929424285889\n",
      "14 epoch time :  1.0638651847839355\n",
      "15 epoch time :  0.8559796810150146\n",
      "16 epoch time :  0.9814233779907227\n",
      "17 epoch time :  0.8490517139434814\n",
      "18 epoch time :  0.8708357810974121\n",
      "19 epoch time :  0.7762899398803711\n",
      "20 epoch time :  0.8401312828063965\n",
      "21 epoch time :  0.9246985912322998\n",
      "22 epoch time :  0.9828791618347168\n",
      "23 epoch time :  0.909233570098877\n",
      "24 epoch time :  0.8909540176391602\n",
      "25 epoch time :  1.3194572925567627\n",
      "26 epoch time :  0.8496527671813965\n",
      "27 epoch time :  0.9592077732086182\n",
      "28 epoch time :  1.0813701152801514\n",
      "29 epoch time :  0.8577678203582764\n",
      "30 epoch time :  0.8178472518920898\n",
      "31 epoch time :  0.9357595443725586\n",
      "32 epoch time :  0.9719023704528809\n",
      "33 epoch time :  0.7746407985687256\n",
      "34 epoch time :  0.9268214702606201\n",
      "35 epoch time :  0.9020340442657471\n",
      "36 epoch time :  0.9463858604431152\n",
      "37 epoch time :  0.8388080596923828\n",
      "38 epoch time :  0.9183952808380127\n",
      "39 epoch time :  0.9266760349273682\n",
      "40 epoch time :  0.918503999710083\n",
      "41 epoch time :  0.8675127029418945\n",
      "42 epoch time :  0.8400609493255615\n",
      "43 epoch time :  0.7789821624755859\n",
      "44 epoch time :  0.8584163188934326\n",
      "45 epoch time :  0.7766327857971191\n",
      "46 epoch time :  1.132089614868164\n",
      "47 epoch time :  1.0776638984680176\n",
      "48 epoch time :  0.858731746673584\n",
      "49 epoch time :  0.7768936157226562\n",
      "50 epoch time :  0.8474652767181396\n",
      "51 epoch time :  0.7807803153991699\n",
      "52 epoch time :  0.8569228649139404\n",
      "53 epoch time :  0.839698314666748\n",
      "54 epoch time :  0.7769327163696289\n",
      "55 epoch time :  1.0465402603149414\n",
      "56 epoch time :  0.7891771793365479\n",
      "57 epoch time :  0.9657034873962402\n",
      "58 epoch time :  0.8178024291992188\n",
      "59 epoch time :  1.0240631103515625\n",
      "60 epoch time :  0.7785420417785645\n",
      "61 epoch time :  0.778972864151001\n",
      "62 epoch time :  0.7791123390197754\n",
      "63 epoch time :  0.9295918941497803\n",
      "64 epoch time :  0.8544948101043701\n",
      "65 epoch time :  1.0125055313110352\n",
      "66 epoch time :  0.945124626159668\n",
      "67 epoch time :  0.8537471294403076\n",
      "68 epoch time :  1.0479614734649658\n",
      "69 epoch time :  0.9258432388305664\n",
      "70 epoch time :  0.8963215351104736\n",
      "71 epoch time :  0.8740673065185547\n",
      "72 epoch time :  0.8724918365478516\n",
      "73 epoch time :  0.8705463409423828\n",
      "74 epoch time :  0.7796204090118408\n",
      "75 epoch time :  0.7788400650024414\n",
      "76 epoch time :  1.0308830738067627\n",
      "77 epoch time :  0.8447353839874268\n",
      "78 epoch time :  0.9332337379455566\n",
      "79 epoch time :  0.7821295261383057\n",
      "80 epoch time :  0.9019958972930908\n",
      "81 epoch time :  0.7824175357818604\n",
      "82 epoch time :  0.7776083946228027\n",
      "83 epoch time :  0.9209246635437012\n",
      "84 epoch time :  0.9297041893005371\n",
      "85 epoch time :  0.8666810989379883\n",
      "86 epoch time :  0.8748528957366943\n",
      "87 epoch time :  0.899662971496582\n",
      "88 epoch time :  0.8543198108673096\n",
      "89 epoch time :  0.8036820888519287\n",
      "90 epoch time :  1.4725885391235352\n",
      "91 epoch time :  0.8621501922607422\n",
      "92 epoch time :  0.8447258472442627\n",
      "93 epoch time :  0.7795531749725342\n",
      "94 epoch time :  0.9130222797393799\n",
      "95 epoch time :  0.7917382717132568\n",
      "96 epoch time :  1.1313185691833496\n",
      "97 epoch time :  0.923846960067749\n",
      "98 epoch time :  0.7972004413604736\n",
      "99 epoch time :  0.8730268478393555\n"
     ]
    }
   ],
   "source": [
    "# begin train\n",
    "epochs = 100\n",
    "torch.backends.cudnn.benchmark = True\n",
    "for i in range(epochs):\n",
    "    net.train()\n",
    "    beginTime = time.time()\n",
    "    for trainImage, trainLabel in dataLoaderTrain:\n",
    "        optimizer.zero_grad()\n",
    "        trainImage = trainImage.to(device)\n",
    "        trainLabel = trainLabel.to(device, dtype=torch.long)\n",
    "        output = net(trainImage)\n",
    "        loss = ceLoss(output, trainLabel)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    net.eval()\n",
    "    for valImage, valLabel in dataLoaderVal:\n",
    "        with torch.no_grad():\n",
    "            valImage = valImage.to(device)\n",
    "            valLabel = valLabel.to(device, dtype=torch.long)\n",
    "            output = net(valImage)\n",
    "            loss = ceLoss(output, trainLabel)\n",
    "    endTime = time.time()\n",
    "\n",
    "    print(i , \"epoch time : \", (endTime - beginTime))\n",
    "    torch.save(net, \"./model/hair.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "071f83251836d5bb3918d2af6501aef1a588d685a567aa45f470f25864dd9495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
